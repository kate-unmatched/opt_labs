# Лабораторная №2

## Дихотомия c Vector

Этот метод реализует метод дихотомии (двоичного поиска) для нахождения минимума функции многих переменных. В
контексте векторов, метод пытается найти точку, в которой функция достигает своего минимального значения, перемещаясь по
пространству векторов.

Устройство алгоритма:

1. Проверка размерностей векторов. Первая строчка убеждается, что векторы `left` и `right`, указывающие начальный и
   конечный
   интервалы поиска, имеют одинаковую размерность. Это необходимо, поскольку операции над векторами требуют, чтобы они
   были одинаковой длины.
2. Инициализация переменных: Устанавливается счётчик итераций в 0, а также вычисляется начальная точка "середины" как
   среднее арифметическое левой и правой границ.
3. Цикл поиска: Цикл будет выполняться до тех пор, пока не будет достигнуто максимальное количество итераций или разница
   между правой и левой границами не станет меньше, чем удвоенное значение `eps` (точность поиска).
4. Вычисление функции в двух точках: В каждой итерации вычисляется значение функции в двух точках, смещённых на `eps`
   влево и вправо от текущей середины. Это делается для определения направления, в котором функция уменьшается.
5. Обновление границ: В зависимости от того, где функция меньше, обновляется левая или правая граница интервала поиска.
   Это
   сужает диапазон поиска к минимуму функции.
6. Вычисление новой середины: После обновления границ вычисляется новая точка середины интервала.
7. Инкремент счётчика итераций: Счётчик итераций увеличивается на 1.
8. Вывод информации о процессе: После выхода из цикла, на экран выводится информация о количестве вызовов функции и
   диапазоне аргументов на последней итерации.
9. Возвращение результата: Метод возвращает точку (вектор) минимума найденного по методу дихотомии.

## Золотое сечение

Этот метод реализует алгоритм поиска золотого сечения для оптимизации функции многих переменных. Поиск золотого
сечения — это метод определения минимума функции, который использует свойства золотого сечения для сокращения диапазона
поиска на каждой итерации. Это позволяет эффективно находить минимум унимодальной функции без производных.

Устройство алгоритма:

1. Проверка размерности векторов: Убедиться, что векторы `left` и `right`, определяющие начальный диапазон поиска, имеют
   одинаковую размерность. Это необходимо для корректной работы алгоритма.
2. Инициализация итераций: Начальное количество итераций установлено в 0.
3. Вычисление границ: Рассчитываются начальные точки `leftBoundary` и `rightBoundary` внутри диапазона `[left, right]`,
   используя
   отношение золотого сечения `REVERSE_GRP`. Это позволяет разделить диапазон поиска на две части, пропорциональные
   золотому сечению.
4. Вычисление значений функции: Находятся значения функции в точках `leftBoundary` и `rightBoundary`.
5. Цикл оптимизации: Цикл продолжается до тех пор, пока не будет достигнуто максимальное количество итераций, либо пока
   разница между `left` и `right` не станет меньше заданной точности `2 * eps`.
6. Условие обновления: Если значение функции в `leftBoundary` больше, чем в `rightBoundary`, обновляется левая граница
   интервала поиска. В противном случае обновляется правая граница. Это сужает диапазон поиска, сохраняя при этом
   пропорции
   золотого сечения.
7. Обновление границ и значений функции: В зависимости от предыдущего условия, границы и значения функции обновляются,
   чтобы продолжить поиск в новом, уже суженном диапазоне.
8. Вывод результатов: По завершению цикла выводится информация о количестве вызовов функции и диапазоне аргументов.
9. Возвращение результата: Возвращает точку минимума, вычисленную как среднее между конечными границами `left` и `right`.

**Особенности метода:**

`REVERSE_GRP` обозначает величину, обратную золотому сечению, и используется для расчета точек `leftBoundary` и
`rightBoundary`.

Метод золотого сечения эффективен для унимодальных функций, где существует один локальный и одновременно глобальный
минимум в заданном интервале.

В отличие от метода дихотомии, который требует сравнения значений функции в двух очень близких точках, метод золотого
сечения использует более широкое разделение точек, что делает его менее чувствительным к ошибкам округления.

## Метод Фибоначчи

Этот метод использует алгоритм Фибоначчи для оптимизации функции многих переменных, целью которого является нахождение
минимума этой функции в заданном диапазоне с помощью последовательности Фибоначчи. Последовательность Фибоначчи
используется для динамического изменения размера интервала поиска, уменьшая его с каждой итерацией и приближаясь к
минимуму функции.

Пошаговое объяснение:

1. Проверка размерности векторов: Убедиться, что начальный `left` и конечный `right` вектора имеют одинаковую
   размерность
   для корректной работы алгоритма.
2. Копирование границ: Создаются копии границ интервала поиска (`a` и `b`), чтобы не изменять исходные вектора.
3. Инициализация переменной `delta`: Эта переменная будет использоваться для вычисления текущего интервала между `a`
   и `b`.
4. Поиск ближайшей пары чисел Фибоначчи: Вызов функции `closestFibonacciPair` для нахождения пары последовательных чисел
   Фибоначчи, для которых разница между длиной интервала (`b.subtract(a).getNorm()`) и продуктом меньшего числа
   Фибоначчи
   и `eps` минимальна. Это определяет количество шагов алгоритма и начальное соотношение разделения интервала.
5. Цикл оптимизации: Пока текущие числа Фибоначчи не совпадают и интервал больше eps, продолжается уточнение границ
   минимума.
6. Расчет точек `x1` и `x2`: Определение двух точек внутри интервала `[a, b]`, которые разделяют его в соотношении,
   соответствующем двум последним числам Фибоначчи. Это позволяет эффективно сужать интервал поиска.
7. Обновление чисел Фибоначчи: Последовательное обновление значений чисел Фибоначчи для следующей итерации.
8. Обновление границ: В зависимости от значений функции в точках `x1` и `x2`, обновляется одна из границ интервала,
   сужая
   тем самым область поиска минимума.
9. Вывод информации о диапазоне аргументов: После завершения всех итераций выводится информация о текущем интервале
   поиска.
10. Возврат результата: Возвращается средняя точка между конечными границами `a` и `b`, предполагая, что это точка
    минимума функции.

Особенности алгоритма:
Последовательность Фибоначчи используется для определения соотношения, в котором разделяется интервал поиска, что
позволяет с каждой итерацией эффективно сокращать этот интервал.
Алгоритм завершается, когда достигнута необходимая точность eps или когда достигнуты последние два числа в подходящей
последовательности Фибоначчи, указывающие на то, что интервал поиска достаточно сужен.
Этот метод является эффективным и экономичным способом нахождения минимума функции, особенно когда точное значение
производной функции трудно получить или оно неизвестно.

## Метод покоординатного спуска

Этот метод является реализацией алгоритма поиска минимума функции методом покоординатного спуска. Целью алгоритма
является нахождение точки в многомерном пространстве, в которой функция принимает минимальное значение.

Исходные данные: у нас есть функция `function`, которую мы хотим минимизировать. Начальная точка `xStart` — это точка, с
которой мы начинаем наш поиск минимума. `eps` — это некоторая маленькая величина, которая определяет точность нашего
решения. `maxIterations` — это максимальное количество итераций, которое мы готовы выполнить, чтобы найти минимум.

Шаги алгоритма:

1. Алгоритм работает итерационно, на каждом шаге пытаясь улучшить текущее приближение к минимуму, изменяя поочерёдно
   каждую
   координату точки.
2. На каждой итерации выбирается одна из координат текущей точки (переменная `coordinateId`), и алгоритм пытается найти
   лучшее значение для этой координаты, при котором значение функции будет меньше.
3. Для этого алгоритм сначала немного уменьшает, а затем увеличивает значение выбранной координаты на небольшое
   число `eps` и
   смотрит, как это влияет на значение функции (`y_0` и `y_1`). Это помогает определить, в каком направлении следует
   двигаться
   для минимизации функции по этой координате.
4. После определения направления, выбранная координата изменяется на некоторый шаг (`step`), уменьшая значение функции.
5. Затем алгоритм использует метод дихотомии (бинарного поиска) для более точного нахождения минимального значения
   функции
   по выбранной координате в пределах заданной точности eps. Метод дихотомии подразумевает деление интервала пополам и
   выбор подинтервала, в котором предположительно находится минимум.
6. Если изменение выбранной координаты оказывается меньше заданной точности `eps`, считается, что по этой координате
   достигнут оптимальный результат. Если оптимизация достигнута для всех координат, алгоритм завершается.
7. Завершение работы. Если на протяжении всех итераций были успешно оптимизированы все координаты или был достигнут
   максимальный предел итераций, алгоритм возвращает текущее положение точки как приближённое значение точки минимума
   функции.

Важно отметить, что алгоритм покоординатного спуска особенно хорошо подходит для функций, которые "хорошо" ведут себя и
имеют чётко выраженный минимум. Однако, его эффективность может сильно зависеть от выбора начальной точки и
шага (`step`).


