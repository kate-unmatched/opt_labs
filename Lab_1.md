# Лабораторная №1

[**Метод половинного деления**](#метод-половинного-деления)

[**Метод золотого сечения**](#метод-золотого-сечения)

[**Метод Фибоначчи**](#метод-фибоначчи)

## Метод половинного деления

Метод половинного деления, также известный как метод бисекции, является одним из простейших и наиболее надёжных
численных методов нахождения корня (точки пересечения с осью абсцисс) унимодальной (имеющей один экстремум на
рассматриваемом интервале) функции. Этот метод применим к функциям, которые непрерывны на заданном интервале,
и основан на принципе промежуточного значения, который утверждает, что для любого числа, лежащего между значениями
функции на концах отрезка, существует хотя бы один корень внутри этого отрезка. Другими словами, если функция на
концах интервала принимает значения с разными знаками, то внутри этого интервала лежит корень.

**Алгоритм:**

Этот код реализует метод половинного деления (бисекции) для поиска корня функции на заданном интервале `[x1, x2]` с
заданной точностью `eps` и ограничением по количеству итераций `maxIterations`. Пошаговое объяснение работы этого кода:

1. Проверка и коррекция интервала. В начале, если начальная точка `x1` больше конечной точки `x2`, они меняются местами.
   Это гарантирует, что `x1` всегда меньше `x2`.

2. Инициализация переменных. Переменная `root` будет хранить текущее приближение корня функции. Переменная `iteration`
   считает количество итераций.

3. Цикл поиска корня. Цикл продолжается до тех пор, пока не будет достигнуто максимальное количество итераций
   `maxIterations` или разница между `x2` и `x1` не станет меньше заданной точности `eps`. Эти условия гарантируют
   остановку алгоритма.

4. Нахождение середины интервала. На каждом шаге цикла вычисляется середина текущего интервала `root = (x1 + x2) * 0.5`.

5. Оценка функции в точках вокруг корня. Вычисляются значения функции слева и справа от найденной середины `root`,
   но с учетом небольшого смещения на `eps`. Это делается для определения направления, в котором следует двигаться для
   уточнения корня. `fRootLeft = function.applyAsDouble(root - eps)` и `fRootRight = function.applyAsDouble(root + eps)`
   позволяют оценить производную функции в окрестности точки `root`.

6. Выбор нового интервала. Если `fRootRight > fRootLeft`, это означает, что функция убывает в окрестности `root`,
   и новым интервалом для поиска становится `[x1, root]`. В противном случае, интервал становится `[root, x2]`. Это
   решение основывается на предположении о том, как меняется знак функции вблизи корня и позволяет эффективно сократить
   область поиска в два раза.

7. Итерации. С каждым шагом цикла количество итераций увеличивается, и интервал поиска уменьшается, что приближает
   к точному нахождению корня.

8. Возврат результата. Как только условия остановки цикла выполнены, переменная `root` содержит последнее вычисленное
   приближение корня функции, которое и возвращается как результат работы функции.

Ключевым моментом здесь является использование `eps` для вычисления значений функции слева и справа от предполагаемого
корня. Это позволяет избежать ситуации, когда `root` находится слишком близко к реальному корню и из-за ограниченной
точности вычислений нельзя однозначно определить, в какую сторону следует корректировать интервал поиска.

**Преимущества:**

- Простота реализации.
- Гарантированное нахождение корня, если он существует в выбранном интервале и функция непрерывна.
- Детерминированность процесса.

**Недостатки:**

- Относительно медленная сходимость по сравнению с другими методами, такими как метод Ньютона или метод секущих.
- Необходимость в выборе начального интервала, в котором функция меняет знак.

## Метод золотого сечения

Метод золотого сечения — это метод поиска экстремума (минимума или максимума) функции на заданном интервале, который
использует принцип золотого сечения для сокращения интервала поиска. Золотое сечение — это деление отрезка на две части
таким образом, что отношение всего отрезка к большей части равно отношению большей части к меньшей, и приблизительно
равно числу Фибоначчи 1.618.

**Алгоритм:**

1. Инициализация интервала: Алгоритм начинается с определения начального интервала `[x1,x2]`, в пределах которого
   предполагается наличие минимума функции. Если `x1` больше `x2`, их значения меняются местами, чтобы гарантировать,
   что `x1 < x2`.
2. Константа `REVERSE_GRP`. Значение `REVERSE_GRP` представляет собой `1 / φ`, где `φ` (примерно 1.618) — константа
   золотого сечения. Это значение используется для расчета точек деления интервала, которые разделяют его в золотом
   отношении.
3. Вычисление границ. На каждом шаге алгоритма вычисляются две точки внутри интервала `[x1,x2]` — `leftBoundary` и
   `rightBoundary`. Эти точки разделяют интервал так, что отношение меньшей части интервала к большей такое же, как и
   отношение большей части к целому интервалу, следуя принципу золотого сечения.
4. Оценка функции. Для каждой из этих точек вычисляется значение функции — `fRootLeft` и `fRootRight` соответственно.
5. Сокращение интервала. Сравниваются значения функции в этих двух точках:

- Если значение функции в левой точке `(fRootLeft)` больше или равно значению в правой `(fRootRight)`, это означает, что
  минимум находится в правой части интервала, и новый интервал поиска будет от `leftBoundary` до `x2`.
- В противном случае, если `fRootLeft` меньше `fRootRight`, минимум находится в левой части, и интервал сокращается
  до `[x1, rightBoundary]`.
- Чтобы искать максимум - нужно поставить условие, что значение функции в левой точке `(fRootLeft)` меньше или равно
  значению в правой `(fRootRight)`

6. Повторение: Процесс повторяется до тех пор, пока разница между `x1` и `x2` не станет меньше заданной точности eps или
   не будет достигнуто максимальное количество итераций `maxIterations`.
7. Результат: По завершении работы алгоритма возвращается средняя точка между `x1` и `x2`, что является приближенным
   значением координаты минимума исследуемой функции на заданном интервале.

**Преимущества метода:**

- Простота реализации. Метод не требует производных функции, что делает его простым в реализации для
  широкого круга задач.
- Эффективность. Метод эффективен для одномерных задач оптимизации, особенно когда вычисление производной
  затруднительно или невозможно.
- Универсальность. Подходит для поиска экстремумов различных типов функций, включая непрерывные и гладкие функции.

**Недостатки метода:**

- Ограниченность. Метод применим только к задачам одномерной оптимизации.
- Зависимость от начального интервала. Точность и скорость поиска зависят от правильного выбора начального интервала.

## Метод Фибоначчи

Метод Фибоначчи для поиска минимума функции — это один из алгоритмов оптимизации, используемых для нахождения
минимального значения функции на заданном интервале. Он основан на свойствах чисел Фибоначчи и принципе сокращения
интервала поиска. Метод применяется для функций, которые унимодальны на интервале поиска, то есть имеют только один
минимум или максимум.

**Алгоритм:**

1. Инициализация. Если начальная точка `x1` больше конечной точки `x2`, они меняются местами, чтобы гарантировать, что
   `a = x1 < x2 = b`. Это обеспечивает правильное направление поиска.
2. Подготовка чисел Фибоначчи. Вызывается функция `closestFibonacciPair(double value)`, которая возвращает пару
   последовательных чисел
   Фибоначчи, таких что длина интервала `[a, b]` меньше или приблизительно равна длине, полученной из отношения
   соответствующих чисел Фибоначчи, умноженного на `eps`. Эти числа используются для расчета промежуточных точек.
3. Итерационный процесс. На каждом шаге интервал `[a, b]` делится на две части в соотношении, определенном
   соответствующими
   числами Фибоначчи. Вычисляются две промежуточные точки `x1` и `x2` внутри интервала `[a, b]`, используя текущие
   значения чисел
   Фибоначчи.
4. Сравнение значений функции. Для каждой из двух промежуточных точек вычисляется значение функции. Сравнение этих
   значений
   показывает, в какой части интервала находится минимум: если `f(x1) < f(x2)`, то минимум находится слева от `x2`, и
   новый
   интервал будет `[a, x2]`. В противном случае, минимум находится справа от `x1`, и новый интервал будет `[x1, b]`.
5. Обновление чисел Фибоначчи и интервалов. После каждой итерации числа Фибоначчи и интервалы обновляются для следующего
   шага. Этот процесс повторяется до тех пор, пока не будет достигнута требуемая точность eps или пока
   последовательность
   чисел Фибоначчи не сойдется.
6. Возврат результата. Возвращается средняя точка последнего интервала `[a, b]`, которая является приближением к точке
   минимума функции.

**Преимущества метода:**

- Высокая эффективность и точность. Метод позволяет достаточно быстро сократить интервал неопределенности, приближаясь к
  точке минимума с заранее заданной точностью.
- Не требует вычисления производных. Это делает метод применимым к широкому кругу функций, включая те, которые не
  дифференцируемы на всем интервале поиска.
- Оптимальность числа шагов. Количество шагов, необходимых для достижения заданной точности, заранее известно и
  определяется выбранным начальным интервалом и точностью, что позволяет эффективно планировать ресурсы вычислений.

**Недостатки метода:**

- Сложность в понимании и реализации. Для корректной реализации метода необходимо правильно подобрать числа Фибоначчи и
  управлять интервалами поиска, что может быть неинтуитивным.
- Зависимость от начального интервала. Необходимо заранее задать интервал, в котором предполагается наличие
  единственного
  минимума, что не всегда возможно без предварительного анализа функции.
- Неэффективность для некоторых типов функций. Для функций с множественными локальными минимумами или очень плоскими
  минимумами метод может быть менее эффективен, так как сложно определить, к какому минимуму происходит сближение.